<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>faceswap训练 | IKEOVE</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="tool" />
  
  
  
  
  <meta name="description" content="内容: 介绍 什么是训练？ 概览 术语   训练数据 选择模型 配置模型 设置 监督训练 停止与恢复 修复错误模型">
<meta property="og:type" content="article">
<meta property="og:title" content="faceswap训练">
<meta property="og:url" content="http://yoursite.com/2020/04/04/faceswap%E8%AE%AD%E7%BB%83/">
<meta property="og:site_name" content="IKEOVE">
<meta property="og:description" content="内容: 介绍 什么是训练？ 概览 术语   训练数据 选择模型 配置模型 设置 监督训练 停止与恢复 修复错误模型">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-04-04T12:00:00.000Z">
<meta property="article:modified_time" content="2020-04-04T12:00:00.000Z">
<meta property="article:author" content="Ringo Hu">
<meta property="article:tag" content="tool">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="IKEOVE" type="application/atom+xml">
  
  <link rel="icon" href="/css/images/favicon.ico">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
    
  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Yanone+Kaffeesatz%3A200%2C300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">

  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Oswald%3A300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">
  
<link rel="stylesheet" href="/css/style.css">


  
<script src="/js/jquery-3.1.1.min.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >
  <link rel="stylesheet" href="/css/fashion.css" >
  <link rel="stylesheet" href="/css/glyphs.css" >

<meta name="generator" content="Hexo 4.2.0"></head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  


<header id="allheader" class="site-header" role="banner" 
   >
  <div class="clearfix container">
      <div class="site-branding">

          <h1 class="site-title">
            
              <a href="/" title="IKEOVE" rel="home"> IKEOVE </a>
            
          </h1>
          
          
            <div class="site-description">Like LiKe, Like like LIKE</div>
          
            
          <nav id="main-navigation" class="main-navigation" role="navigation">
            <a class="nav-open">Menu</a>
            <a class="nav-close">Close</a>

            <div class="clearfix sf-menu">
              <ul id="main-nav" class="menu sf-js-enabled sf-arrows"  style="touch-action: pan-y;">
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/">Home</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/archives">Archives</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/categories">Categories</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/tags">Tags</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/about">About</a> </li>
                    
              </ul>
            </div>
          </nav>

      </div>
  </div>
</header>


  <div id="container">
    <div id="wrap">
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-faceswap训练" style="width: 66%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      faceswap训练
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2020/04/04/faceswap%E8%AE%AD%E7%BB%83/" class="article-date">
	  <time datetime="2020-04-04T12:00:00.000Z" itemprop="datePublished">April 4, 2020</time>
	</a>

      
	<span id="busuanzi_container_page_pv">
	  This post has been read by<span id="busuanzi_value_page_pv"></span> person
	</span>

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="内容"><a href="#内容" class="headerlink" title="内容:"></a>内容:</h4><ul>
<li>介绍</li>
<li>什么是训练？<ul>
<li>概览</li>
<li>术语</li>
</ul>
</li>
<li>训练数据</li>
<li>选择模型</li>
<li>配置模型</li>
<li>设置</li>
<li>监督训练</li>
<li>停止与恢复</li>
<li>修复错误模型<a id="more"></a>

</li>
</ul>
<p><strong>注意</strong>：该文只保证写时有效（2019/09/29），作者尽量保存更新。</p>
<h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>大多数人在初学faceswap时总是不知所措，错误频出。犯错不是坏事，这是我们学习的方式，并且错误能让我们在深入理解之前更好的明白程序执行的过程。</p>
<p>这篇文章中我将会介绍如果训练一个模型。这里有许多模型，每个模型也有许多选项，我不会一一详述，但希望这些足够让你做出你自己的理智的选择。如果你还没有准备好为训练生成你的人脸数据集，那么暂且停止，先去回顾如何提取人脸数据集。</p>
<p>这篇文档里包含大量专业背景知识，我建议你首先对它们进行熟悉。机器学习是一个复杂的概念，但我会尽可能地拆解它们使其变得更加通俗易懂。对神经网络如何工作以及相关的数据的作用有一个基本的了解会大大提高你实现一个成功换脸的几率。</p>
<p>在此我使用GUI界面作用例，但在命令行操作模式下的原则也是一样的（所有GUI上显示的选项同样在命令行模式下也有设定）。</p>
<h4 id="什么是训练？"><a href="#什么是训练？" class="headerlink" title="什么是训练？"></a>什么是训练？</h4><h5 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h5><p>从最高层面上来看，训练是教会我们的神经网络（NN）如何去创造一张人脸的过程。大多数模型主要由两个部分组成：</p>
<ol>
<li><p><strong>编码器</strong>（Encoder）<br>这是一个将大量的人脸数据作为输入然后将它们编码为一种以“向量（vector）”为格式的表现形式的过程。值得注意的是，这并不是在学习对输入的每一张人脸都能有一个精确的表示，而是试图创建一个算法以用于之后重建人脸时能尽可能地接近输入的人脸数据。</p>
</li>
<li><p><strong>解码器</strong>（Decoder）<br>这是一个试图将编码器创建出来的向量再解码为人脸的表现形式的过程，并尽可能地与输入的人脸相贴近。</p>
</li>
</ol>
<p>一些模型的结构可能有些轻微的不同，但基本原则都是保持一样的。</p>
<p>神经网络需要知道怎样更好的对人脸进行编码和解码，通常使用以下两个主要工具：</p>
<ol>
<li><p><strong>丢失</strong>（Loss）<br>对于输入模型中的每一批人脸数据，神经网络会对每一张人脸使用当前的编码和解码算法进行重新生成，然后与初始人脸进行比较。再根据自己的评估方式打出一个分数（丢失值），并相应的更新它的权重（weights）。</p>
</li>
<li><p><strong>权重</strong>（Weights）<br>一旦模型对重建的人脸的效果进行评估后，它就会更新权重。这些会反馈到编/解码算法中去。若权重始终朝一个方向变化，但对重建出来的人脸的评估结果不如之前，那么模型就会知道权重的调整方向错误，后面就可以往另外的方向调整权重了。如果评估的效果提升了，那么模型就知道后续应该继续往这个方向调整权重。</p>
</li>
</ol>
<p>模型会重复多次上述过程，不断地根据丢失值更新权重，理论上会不断提升效果，直到你认为已经有足够多地学习足以有效地重建人脸，或丢失值停止下降。</p>
<p>现在我们对于神经网络做了什么以及它如何学习创建人脸有了基本地概念，那么如何将之应用到换脸中去呢？你可能注意到了，在上面地分析中讲到神经网络学习如何从一堆人脸数据中重建这些人脸，这不是我们想要的。我们想要的是从一堆人脸数据中重建其他人的人脸。为了达到这个目的，我们的神经网络需要做下面两件事情：</p>
<ol>
<li><p><strong>共享编码器</strong>（Encoder）<br>当我们训练我们的模型时，我们输入了两组训练集。训练集A（我们想要替换的原始人脸）和训练集B（我们想放入视频中的交换人脸）。想要实现换脸的第一步就是共享训练集A和训练集B的编码器。其方法为用两组不同的人脸训练出同一个算法。这是尤其重要的，由于我们最终的目的是告诉神经网络将一张人脸的编码解码为另外一张人脸，编码器因此需要扫描和学习我们想要交换的两组人脸数据集。</p>
</li>
<li><p><strong>交换解码器</strong>（Decoder）<br>在我们训练模型时，我们训练出了两种解码器。解码器A用于将编码向量重建为人脸A,解码器B则用于将编码向量重建为人脸B。当进行最终的人脸交换时，我们交换解码器，由于编码器是用了两组人脸数据集进行训练的，所以模型会用编码器编码人脸A，但是后面会使用解码器B来重建人脸，最终在模型输出上就会导致人脸交换的效果。</p>
</li>
</ol>
<h5 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h5><p>有一些常见的机器学习术语你会在使用faceswap中见到。为了方便，先在这里展出一份词汇表：</p>
<p>Batch（批次）：一个批次即同一次向神经网络输入的一组人脸数据集。</p>
<p>Batch Size（批尺寸）：批尺寸即一次向神经网络输入的人脸数据的个数。批尺寸为64意味着一次向神经网络输入64张人脸，丢失和权重的更新是以一批次的人脸数据来计算的。更大的批尺寸会让训练更快，同时也会带来更高的一般化。小的批尺寸会让训练变慢，但却能更好的分辨每张人脸之间的差异。在不同的训练阶段调节批尺寸是有好处的。</p>
<p>Epoch（时期）：一个时期即神经网络对输入的人脸数据进行一次完整的表达。例如，如果你有一个包含有5K张人脸的文件夹，一个时期即模型扫描了所有的5K张人脸，两个时期即模型扫描所有的5K张人脸两次。以此类推。就faceswap而言，时期并不是一个真正有效的策略。由于模型是要通过两组数据集来进行训练的（人脸A和人脸B），除非两组人脸数据集包含有完全相同的人脸个数（非常不可能），否则不可能在一个时期内就计算完拥有不同人脸数目的两组数据集。</p>
<p>Example（范例）：在faceswap中，范例即“人脸”的别称。本质上就是表示输入神经网络中的一张人脸。如果一个模型扫描了10个范例，也就是说扫描了10张人脸图像。</p>
<p>EG/s（每秒范例图形数）：每秒神经网络扫描的范例数，在faceswap中也就是表示模型每秒处理的人脸数目。</p>
<p>Iteration（迭代）：一次迭代即一个批次的人脸数据被神经网络处理了。批尺寸为64的10次迭代意味着有640张人脸数据被模型扫描过。</p>
<p>NN：神经网络的简称。</p>
<h4 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h4><p>数据的质量对于你的模型的重要性是不可估量的。有了合适的数据一个小的模型也能有很好的表现，同样的，没有一个模型能在差数据的条件下产生好的效果。对于你的模型而言两边最少都要有500张不同的人脸图片。数据越多，差别越大，效果越好。需要指出一点的是，合理的图片数量应该是在1000到10000之间。超过这个界限的图片数量反而会伤害到训练效果。</p>
<p>太多相似的图片并不会有助于你的模型。你需要尽可能多的以不同的角度，不同的表情，以及不同的光照条件下拍摄的人脸图片。针对特定的场景来训练模型是一种常见的误解，这是一种“记忆化”，而不是你希望达到的效果。你需要训练模型从所有的角度，所有的表情以及所有的光照条件去理解一张人脸，然后用另外一张包含所有的角度，所有的表情以及所有的光照条件的人脸去替代它。因此，你需要从尽可能多的不同资源中去建立一个训练集，无论训练集A或训练集B都是如此。</p>
<p>不同角度的替代人脸和被替代人脸是至关重要的，神经网络只能从它看到的东西中学习。如果95%的人脸是直面摄像头而只有5%的侧面，那么模型将会花费很长时间去学习如何创建侧脸。如果它看到的侧面太少，可能都没有一点办法去创建侧脸。理想情况下你要尽可能地平均分配不同角度，不同表情以及不同光照条件下的人脸数目。</p>
<p>同样的重要地是，在训练集A和训练集B两边尽可能多地匹配角度/表情/光照条件。如果在训练集A中有大量地侧面图片而在训练集B中没有侧面图片，那么模型就会由于解码器B缺少信息而不能创建侧面镜头从而导致在侧面角度时就不能进行换脸。</p>
<p>训练数据的质量通常要求不能模糊，应保持高品质（清晰细致）。然而，训练集中有一些不清楚或部分模糊的图片也是可以的，在最终的换脸效果中也会有一些人脸变得不清楚/低分辨率/模糊。所以让神经网络看到的图片类型也是很重要的，它会对这些进行忠实的重建。</p>
<p>关于创建训练集的更多详情请参阅提取指导。</p>
<h4 id="选择模型"><a href="#选择模型" class="headerlink" title="选择模型"></a>选择模型</h4><p>Faceswap上有许多可用的模型，并且更多的模型还在不断增加。每一个模型的质量是高度主观化的东西，因此这里只会对每一个（当前）可用的模型进行简短的介绍。你需要考虑多种因素来最终决定哪一个模型最适合你，因此这里没有绝对的答案。每一个都有其优缺点，但如前文所提到的，最重要的因素就是数据的质量，没有模型能处理数据问题。</p>
<p>你会看到上文提到的输入输出尺寸（例如64px输入/输出）。这是指输入模型人脸图像的尺寸和从模型中生成输出的人脸图像的尺寸。所有输入到模型的人脸都是方形的，因此一个64px的图片是高为64像素，宽为64像素。更高分辨率的输入会带来更好的换脸效果也是一个常见的误解。虽然有帮助，但并不是适用于所有的情况。神经网络是在学习如何使用一种算法来对人脸进行编码，再使用这种算法进行解码，这仅仅是需要足够的数据来创建一种稳固的算法。输入分辨率和输出质量没有直接的联系。</p>
<p>值得注意的是，模型越大，训练所需的时间越长。Original模型在使用英伟达GTX 1080的条件下进行训练通常需要12-48个小时，Villain模型在使用同一硬件的条件下所耗时间会超过一周。通常认为一个模型在两倍输入尺寸的条件下会花费两倍时间，但这是错误的，时间至少为原来的四倍甚至更久。这是由于一个64px的图像有4096个像素点，然而一个128px的图像有16384个像素点，是先前的四倍。除此之外，模型还需要额外处理增加的数据量，训练的时间也会迅速累增。</p>
<ul>
<li><p>Lightweight（64px输入，64px输出）</p>
<ul>
<li>这是一个极度精简的模型，设计用于在显存小于等于2GB的GPU上运行faceswap。这并不是所谓的“基础版本”，而是能让用户在低端硬件条件下去训练模型。在高端GPU上训练速度会非常快，这对于在进行更加复杂的模型训练之前先一步看到换脸效果的好坏是非常有用的。</li>
</ul>
</li>
<li><p>Original（64px输入，64px输出）</p>
<ul>
<li>这是最原始的模型。但依旧能提供很好的效果，并且能有效的让你理解数据集的质量的确是换脸效果的最大影响因素之一。</li>
</ul>
</li>
<li><p>IAE（64px输入，64px输出）</p>
<ul>
<li>这个模型的结构与其他模型略有不同。它是有一个共享的编码器和一个共享的解码器，但有三个中间层（一个对于训练集A，一个对于训练集B，一个共享）位于编码器和解码器之间。这种结构方式用于更好的分离特性。</li>
</ul>
</li>
<li><p>Dfaker（64px输入，128px输出）</p>
<ul>
<li>该模型在Original模型的基础上利用了一些不同的技术，特别是能将输入扩展为更高质量的输出。尽管该模型出来已经有一段时间了，却依旧能达到很好的效果，虽然缺少自定义选项但也使得它成为一种简单的“点击即用”的模型。</li>
</ul>
</li>
<li><p>Unbalanced（64-512px输入，64-512px输出）</p>
<ul>
<li>这是一个强大的模型，拥有大量的方式去自定义和提升模型，但这要求有许多的专业技能和知识去了解如何得到一个好的效果。实际上可以说已经被“RealFace”模型取代了。同时由于这个模型过于注重解码器B，以至于在反转交换（将人脸B替换人脸A，而不是将人脸A替换人脸B）时的效果不太好。</li>
</ul>
</li>
<li><p>DFL-H128（128px输入，128px输出）</p>
<ul>
<li>该模型实际上是和Original模型有完全相同的编码和解码器，但后面会使用128px的输入代替64px的输入，再将图像压缩为Original模型一半大小的人脸图像。更小的“隐含空间”在质量上与Original模型相比有一些下降，从而抵消了较大的输入尺寸。</li>
</ul>
</li>
<li><p>DFL-SAE（64-256px输入，64-256px输出）</p>
<ul>
<li>该模型包含了两个不同的网络结构，一个基于Original模型的共享编码器和独立解码器，另一个则基于IAE模型（共享中间层）。它拥有大量的自定义选项，提供更多的细节，但会导致一些特征痕迹（人脸A的一些特性可能仍然会留在已用人脸B替换的结果中）。</li>
</ul>
</li>
<li><p>Villain（128px输入，128px输出）</p>
<ul>
<li>该模型可能是最细致的模型了，但同时也会有更大的显存要求，并且在有限的资源上进行训练时能提供低标准颜色匹配（sub-par color matching）。著名的史蒂夫·布塞米（Steve Buscemi）/珍妮弗·劳伦斯（Jennifer Lawrence）的换脸视频就是使用了这种模型。由于该模型没有任何的自定义选项（除了一个低内存模式），所以如果你想不用任何设置就能得到一个很好的效果，那么该模型是一个适合的选择。</li>
</ul>
</li>
<li><p>Realface（64-128px输入，64-256px输出）</p>
<ul>
<li>该模型是Unbalanced模型的继任者。它借鉴了Unbalanced模型和Dfaker模型并在其上继续发展。该模型是高度可定制化的，但最好是在你明白你在做什么以及这些设置会有什么影响之后再来设置这些选项。和Unbalanced模型一样由于过于注重解码器B，以至于在反转交换（将人脸B替换人脸A，而不是将人脸A替换人脸B）时的效果不太好。</li>
</ul>
</li>
<li><p>Dlight（128px输入，128-384px输出）</p>
<ul>
<li>该模型是Dfaker模型的一个高分辨率变种，使用自定义扩展器专注于扩展人脸分辨率。该模型是最近才出现的同时非常容易配置。</li>
</ul>
</li>
</ul>
<h4 id="配置模型"><a href="#配置模型" class="headerlink" title="配置模型"></a>配置模型</h4><p>好了，现在你已经选择了你的模型，让我们开始训练吧！等一等，我理解你急不可待的心情，但你首先可能需要去对模型的一些特殊选项进行设置。这里我会用GUI做示范，但配置文件（使用命令行）能在你的faceswap文件夹的faceswap/config/train.ini处找到。</p>
<p>我不会深入到每一个模型的选项，这里有那么多的模型并且实时为新模型进行更新是一件艰难的事情，但我会对一些常用的选项进行一个概述。主要针对会对所有模型都会产生影响的全局选项。所有的选项都有工具提示，将鼠标悬停在选项之上去得到更多的功能信息。</p>
<p>进入模型配置面板，Settings-&gt;Configure Train Plugins…</p>
<ul>
<li><p>Global</p>
<ul>
<li>这里的选项将会对所有模型都起作用。</li>
<li>该页上的所有选项，除Learning Rate只在创建一个新模型时起作用之外，其余的所有被选定的选项在你开始训练一个模型时就会针对这个模型被“锁定”，之后所有的改变对于此模型无效，只有当你重新开始训练时设置才会被重载。</li>
<li>Face<ul>
<li>作用于输入模型的人脸数据的选项</li>
<li>Coverage<ul>
<li>这是资源图片输入到模型的量。图片以中心为基准裁剪出量给出的百分比。覆盖百分比越高，一张图片中输入到模型的人脸范围也就越大。100%即不加裁剪全部输入。</li>
<li>直觉上可能觉得高覆盖率总是好的，但并非如此。这是一个权衡过程。高覆盖率意味着人脸的大部分会被交换，但模型的输入尺寸总是固定的，由于更多的信息需要被包含在相同的尺寸图像中，故将导致最终的换脸结果缺少细节。</li>
</ul>
</li>
</ul>
</li>
<li>Mask<ul>
<li>使用面罩进行训练的选项。</li>
<li>设置面罩是指出图片的那一部分区域是重要的一种方法。通常将人脸包含在面罩内以表示重要，其他部分放在面罩外作为无关紧要的部分。</li>
<li>使用面罩进行训练用于两个目的：<ol>
<li>将训练专注在人脸区域，让模型更少关注背景。这能大大提高学习速度，同时确保不会占用空间去学习那些不重要的背景细节。</li>
<li>强化学习过的面罩还能用于转换阶段。虽然在当前的实现过程中，转换时使用强化学习过的面罩与标准面罩相比是否能提供更好的效果这件事是有争议的，但在训练时使用面罩起码保证了你有这个选择。</li>
</ol>
</li>
<li>注意：如果你使用面罩来训练，那么无论是训练集A还是训练集B的文件夹中你都需要提供一个包含所有人脸的校准文件。</li>
<li>Mask Type<ul>
<li>用于训练的面罩类型。使用面罩时你必须将你需求的面罩加入到校准文件中去。可以使用面罩工具进行增加或更新面罩。关于面罩的更多信息可参看提取教程。</li>
</ul>
</li>
<li>Mask Blur Kernel<ul>
<li>这用于轻微模糊面罩边缘。它将有效移除面罩的生硬边界，使得人脸与背景的边界变得更加的柔和自然。这有助于那些少量计算的面罩。是否开启以及设置什么值都取决于你。默认值也是可以的，你也可以使用Mask Tool去试验。</li>
</ul>
</li>
<li>Mask Threshold<ul>
<li>这个选项不会影响使用面罩的校准（extended，components），由于它们是二进制的（面罩只有“开”或者“关”）。而对于使用面罩的神经网络来说，由于面罩不是二进制并且有不同级别的不透明度，这个选项会导致面罩在某些情况下出现斑点。增加阈值使得面罩的部分变得接近透明，乃至完全透明，或者使得面罩的部分变得接近遮挡，乃至完全遮挡。同样的，这个数值也视情况而定。</li>
</ul>
</li>
<li>Learn Mask<ul>
<li>在早期，这个选项是否有益于面罩的强化学习是有争论的。开启这个选项会花费更多的显存，所以我倾向于关闭它，但如果你想在转换中使用这个预期的面罩，那么你应该开启这个选项。</li>
</ul>
</li>
</ul>
</li>
<li>Initialization<ul>
<li>此处设置用于初始化你的模型。</li>
<li>正如在训练概览中提到的那样，模型会在每次迭代结束时更新权重。初始化则用于设置初始权重。你可将之视为在开始对模型提供的帮助。根据了解我们的神经网络将会用来做什么，我们来设置一个能帮助模型有一个好的起跳点的权值。</li>
<li>默认的初始化方法为“he_uniform”，这将从均匀分布中抽取样本。这里不会深入介绍不同的初始化方法并理解它们的功能，而只会涉及到本区域默认所显示的一些方法选项。</li>
<li>需要注意的是一些模型在内部为模型的某些层设定了初始化方式，所以这些层不会被此设置影响。但是对于那些没有进行明确设定的层和模型来说，其初始值会随着设定的选项而改变。</li>
<li>已存在的两种初始化方式能同时使用（同时使用不会有什么副作用）。我倾向于两者并用。</li>
<li>ICNR Init<ul>
<li>该初始化方式仅用于扩展图层。标准初始化方式在使用神经网络进行扩展时会导致输出图片出现“棋盘”的人工痕迹。这种初始化方式就试图消除这种人工痕迹的出现。</li>
</ul>
</li>
<li>Conv Aware Init<ul>
<li>卷积感知初始化应用于模型内的所有卷积层。这种初始化方式背后的原理是它考虑到了卷积网络的目的并相应的初始化权重。理论上这将导致更高的准确性，更低的丢失以及更快的收敛。</li>
<li>注意：初始器在启动时会带来更多的显存消耗，因此建议先使用一个低批尺寸来启动模型，然后再用你想要的批尺寸来重启模型。</li>
<li>注意：初始器在多GPU条件下不可用，如果你使用多GPU进行训练，那么你应该先在单GPU上启动训练，然后停止模型，再使用多GPU方式继续。</li>
</ul>
</li>
</ul>
</li>
<li>Network<ul>
<li>此处设置作用于模型中的图层。</li>
<li>这些选项可被模型中的一些图层所使用。</li>
<li>Subpixel Upscaling<ul>
<li>这是神经网络内用于扩展图像的替代方法。它实际上和默认的像素改组层做了完全相同的工作，只是使用了不同的TensorFlow操作方式。由于并不会产生什么不同所以我建议将它关闭（未来可能会被移除）。</li>
</ul>
</li>
<li>Reflect Padding<ul>
<li>一些模型，尤其是Villain模型，和DFL-SAE模型的部分情况下，在最终换脸成果的交换区域边缘周边会出现明显的“灰框”。该选项修改卷积层中使用的填充类型以减轻这种人工痕迹。我只推荐在这两种模型中开启这个选项，其余情况关闭。</li>
</ul>
</li>
</ul>
</li>
<li>Loss<ul>
<li>使用的丢失函数。</li>
<li>这里有很多不同的方法去计算丢失，对于神经网络来说要关心训练的模型效果怎么样。我不会过于详细的介绍每一个可用的函数，因为这将是一个漫长的过程以及关于这些函数在网络上有大量的信息。</li>
<li>Loss Function<ul>
<li>最流行的丢失计算方法是MAE（Mean Absolute Error）和SSIM（Structural Similarity），个人更偏爱SSIM。</li>
</ul>
</li>
<li>Penalized Mask Loss<ul>
<li>这个选项决定是否对人脸区域之外的图像给予更少的关注，而注重于人脸区域之内的图像。该选项应始终设置为可用。</li>
</ul>
</li>
</ul>
</li>
<li>Optimizer<ul>
<li>和优化器相关的选项。</li>
<li>优化器控制神经网络的学习速率。</li>
<li>Learning Rate<ul>
<li>除非遇到模型崩溃（所有图像都变为纯色块，同时丢失处于高位且无法恢复），否则一般保持默认不做理会。不同于该页面上的其他参数，调节这个值能作用于已存在的模型。</li>
<li>学习速率决定了每次迭代权重上下调节的幅度。直觉上可能会说学习速率越高越好，但并非如此。模型的学习是为了尽可能的得到更低的丢失，而学习速率太高将不断地在最低值上下波动导致不会学习任何东西，过低的学习速率又可能会让模型跌至谷底进而认为已经到达最低点导致停止提升。</li>
<li>你可以想象为下山。你想到达最低点，因此你一直往下走，然而，下山的路并不全是下坡，路上还有许多小的丘陵和山谷，学习速率需要足够高以便能够跨过这些小的山谷，但又不能太高以至于一下子跳到了下一座山的山头（即把最低点也当作山谷跳过去了）。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Model</p>
<ul>
<li>这里的设置是单独针对每一种模型的。</li>
<li>与之前提到的一样，我不会详细介绍模型的每一项配置。插件与插件之间千差万别。但是我会介绍那些你可能在各种插件中常见的选项。一如既往的，每个选项你都能从工具提示中获取更多信息。</li>
<li>Lowmem<ul>
<li>一些插件有“低内存”模式，允许你在更少的显存条件下运行模型的精简版本，但代价是质量会更差。</li>
</ul>
</li>
<li>Input size<ul>
<li>一些插件允许你调节输入模型的图片尺寸。输入图片永远是正方形，因此这个尺寸为输入模型的图片的宽或高的像素值。不要相信大尺寸输入就等于更好的质量，并非永远如此。一个模型能否有一个好质量也是由许多其他的因素来决定的。而更大的输入尺寸会在处理过程中对于显存的要求有指数级的增长。</li>
</ul>
</li>
<li>Output size<ul>
<li>一些插件允许你调节模型生成的输出图片的尺寸。输入尺寸和输出尺寸不要求一样，因为一些模型包含有扩展器能返回尺寸大于输入图片的输出图片。</li>
</ul>
</li>
</ul>
</li>
<li><p>Trainer</p>
<ul>
<li>配置设置页面的最后一个标签页是用来设置训练器的，又叫“数据强化”选项。</li>
<li>一个神经网络需要扫描很多很多不同的图片，为了更好的学习人脸它会在输入的图片上面进行多种操作。这即称为“数据强化”。和提示中讲到的那样，标准设置适用于99.9%的情况，所以只有在你明白选项的具体作用的情况下才能去修改它们。</li>
<li>Evaluation<ul>
<li>评估训练状态的选项。</li>
<li>Preview Images<ul>
<li>这里设置用于交换的训练集A和训练集B显示在预览窗口上图片的个数。</li>
</ul>
</li>
</ul>
</li>
<li>Image Augmentation<ul>
<li>这是施加在输入模型的人脸图片上的一些操作。</li>
<li>Zoom Amount<ul>
<li>在输入到神经网络之前，对人脸进行放大或缩小的百分比值，帮助模型处理错误校准。</li>
</ul>
</li>
<li>Rotation Range<ul>
<li>在输入到神经网络之前，对人脸进行顺时针或逆时针旋转的百分比值，帮助模型处理错误校准。</li>
</ul>
</li>
<li>Shift Range<ul>
<li>在输入到神经网络之前，对人脸进行上下，左右偏移的百分比值，帮助模型处理错误校准。</li>
</ul>
</li>
<li>Flip Chance<ul>
<li>水平翻转脸部，帮助创建更多的角度以供神经网络用来学习。</li>
</ul>
</li>
</ul>
</li>
<li>Color Augmentation<ul>
<li>这些强化作用于输入到模型的人脸图片的对比度/色彩，使得神经网络在色彩差异方面表现得更加优秀。</li>
<li>Color Lightness<ul>
<li>对输入的图片进行上下调节亮度的百分比值，帮助处理不同的光照条件。</li>
</ul>
</li>
<li>Color AB<ul>
<li>调节训练集A/B里的人脸图片的CIE-L*a*b*颜色空间百分比值。帮助神经网络处理不同的色彩状态。</li>
</ul>
</li>
<li>Color CLAHE Chance<ul>
<li>调节图像的“对比度有限调节直方图均衡化（Contrast Limited Adaptive Histogram Equalization）”百分比值。CLAHE是一种尝试定位对比度变化的对比方法。帮助神经网络处理不同的对比度。</li>
</ul>
</li>
<li>Color CLAHE Max Size<ul>
<li>CLAHE算法“网格尺寸”的最大值。这将应用于输入图像。更高的数值会带来更高的对比度应用。帮助神经网络处理不同的对比度。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>一旦你设置好了你想要的模型配置，点击OK去保存这些配置以及关闭窗口。</p>
<p><strong>注意</strong>：点击OK将会保存所有标签页的设置，所以请确保你认真的检查过。你可以点击Cancel去取消你的修改或者按Reset去恢复所有的设置值为默认状态。</p>
<h4 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h4><p>现在你已经准备好了你的人脸数据，你也配置好了你的模型，是时候开始行动了！</p>
<p>在GUI中点击Train标签页：<br>在这里我们告诉faceswap资源的存储位置，使用的模型，然后真正的开始训练。</p>
<ul>
<li><p>Faces</p>
<ul>
<li>这里设置人脸数据集的存储位置，以及它们各自的校准文件（如果需要）。</li>
<li>Input A<ul>
<li>这里设置你提取过程中获得的人脸A的训练集的文件夹位置。这些人脸会从原始场景中被移除然后使用交换的人脸替代。这个文件夹中应包含大约1000-10000张人脸。</li>
</ul>
</li>
<li>Alignments A<ul>
<li>如果你使用面罩或者“”Warp to Landmarks”进行训练那么这里就需要指明你的人脸数据A的校准文件，这个文件会在提取过程中被生成。如果这个文件存在于你的人脸数据文件夹且命名为“alignments.json”，那么程序会自动选择它。必需保证人脸A数据文件夹中的每一张人脸都在校准文件中包含有其信息，否则训练会失败。因此你可能需要合并一些校准文件。关于如何为训练准备校准文件的更多信息请参考提取指导。</li>
</ul>
</li>
<li>Input B<ul>
<li>这里设置你提取过程中获得的人脸B的训练集的文件夹位置。这些人脸会替代原始场景中的人脸。这个文件夹中应包含大约1000-10000张人脸。</li>
</ul>
</li>
<li>Alignments A<ul>
<li>如果你使用面罩或者“”Warp to Landmarks”进行训练那么这里就需要指明你的人脸数据B的校准文件，这个文件会在提取过程中被生成。如果这个文件存在于你的人脸数据文件夹且命名为“alignments.json”，那么程序会自动选择它。必需保证人脸B数据文件夹中的每一张人脸都在校准文件中包含有其信息，否则训练会失败。因此你可能需要合并一些校准文件。关于如何为训练准备校准文件的更多信息请参考提取指导。</li>
</ul>
</li>
</ul>
</li>
<li><p>Model</p>
<ul>
<li>这里设置你想要训练的模型的有关选项。</li>
<li>Model Dir<ul>
<li>模型保存的位置。选择一个空文件夹保存新的模型。也可以选择一个已包含模型的文件夹以重启训练。</li>
</ul>
</li>
<li>Trainer<ul>
<li>你想用来进行训练的模型。前文已经介绍了。</li>
</ul>
</li>
<li>Allow Growth<ul>
<li>英伟达专用。允许TensorFlow GPU使用“allow_growth”的配置选项。此选项阻止TensorFlow在启动时就分配全部的GPU显存，但会导致显存碎片化和性能降低。只有当你在训练时遇到问题（尤其是cuDNN错误）才开启。</li>
</ul>
</li>
</ul>
</li>
<li><p>Training</p>
<ul>
<li>训练专用设置。</li>
<li>Batch Size<ul>
<li>前文有解释，批尺寸是一次输入模型的人脸图像数量。提高该值会增加显存使用但能一定程度上加速训练。降低该值能提供一种调整规则帮助模型更好的概括人脸。尽管大的批尺寸能加快训练，但8-16范围内的批尺寸数值似乎能产生更好的质量。是否另外的调整规则能替代或消除这种需求依旧是一个悬而未决的问题。</li>
</ul>
</li>
<li>Iterations<ul>
<li>自动停止训练前的迭代次数。这仅仅是为了自动化或者保证训练能在一定次数后停止。但通常你会在预览的效果达到预期而手动停止训练。</li>
</ul>
</li>
<li>GPUs<ul>
<li>英伟达专用。用于训练的GPU个数。如果你的系统中包含有多个GPU，你最多可以使用8个GPU来加速训练。但注意这个加速效果不是线性增长的，加入的GPU越多，新加入的GPU产生的效果就越少。后面它也允许你通过拆分到各个GPU中而增大训练的批尺寸。速度和显存数值最差的GPU将会成为你的瓶颈，所以最好的工作方式是在同样的GPU上进行训练。</li>
</ul>
</li>
<li>No Logs<ul>
<li>在TensorBorad和GUI上显示的丢失和模型日志能够用于分析数据。关闭这个选项将意味着你不再能获取到这些数据，实际上，没有任何理由去关闭记录，所以通常它不应该被勾选。</li>
</ul>
</li>
<li>Warp To Landmark<ul>
<li>和之前介绍的一样，数据被弯曲好让神经网络能够学习如何去重建一张人脸。弯曲地标是一种不同的弯曲方式，它尝试去随机化弯曲和另外一侧的数据集相似的人脸（例如从训练集A中发现了一张和训练集B中相似的人脸，然后就对它进行一些随机化弯曲）。这种方式与标准随机化弯曲相比有什么好处或不同目前尚无定论。</li>
</ul>
</li>
<li>No Flip<ul>
<li>随机翻转图像去帮助提高神经网络所看到的数据量。但由于人脸是不对称的，所以在某些情况下可能效果并不让人满意（例如一边脸上有痣）。通常情况下默认不勾选，或者只是在开始训练的时候不勾选，之后的过程中对于某些交换你可能想不翻转。</li>
</ul>
</li>
<li>No Augment Color<ul>
<li>Facesawp进行颜色增强（前面介绍过）。这确实能帮助训练集A与B之间匹配颜色/光照/对比度，但有时候可能不希望如此，那时就可以禁用此项。</li>
</ul>
</li>
</ul>
</li>
<li><p>VRAM Savings</p>
<ul>
<li>节约显存的优化设置（英伟达专用）。</li>
<li>Faceswap提供了一些节约显存的优化选项，以便能让用户在性能可能不太够的情况下进行训练模型。不幸的是这些优化目前只适用于英伟达的显卡。这可能是最后一根救命稻草。如果你能够在不开启这些选项的情况下以至少6-8的批尺寸进行模型训练，那么你就不需要开启这些选项，因为会带来速度损失。所有选项都可独立作用，以节约堆栈空间。</li>
<li>Memory Saving Gradients<ul>
<li>MSG是一种在计算成本中节约显存的优化方案。理想情况下它能以提高20%的训练时间换来减少一半的显存消耗。这是你应该首先尝试的选项。</li>
</ul>
</li>
<li>Optimizer Savings<ul>
<li>通过在CPU而不是GPU上进行一些优化计算而节省出一笔可观的显存消耗。但这同时会增加系统内存消耗和降低训练速度。这应该是你尝试的第二选项。</li>
</ul>
</li>
<li>Ping Pong<ul>
<li>这是被逼无奈下最后也是最差的办法，但或许会对你有用。这本质上是将模型一分为二，一次只训练一半的模型。能够节约40%的显存消耗但会花费超过两倍的时间来训练模型。这应当是你最后考虑的选项。</li>
<li><strong>注意</strong>：TensorBoard的记录和绘图功能在开启此选项的条件下不可用。</li>
<li><strong>注意</strong>：预览图界面不再显示图片直到模型的两部分都已完成了一轮训练。</li>
</ul>
</li>
</ul>
</li>
<li><p>Saving</p>
<ul>
<li>计划保存模型文件的选项。</li>
<li>Save Interval<ul>
<li>多久保存一次模型到磁盘。当模型在保存时不会进行训练，因此你可以通过提高该值以得到略微的训练速度提升（这样就不用频繁等待模型被写入磁盘）。但该选项作为你的“故障保护”或许你也不应该将数值调得太高。如果一个模型在训练过程中崩溃了，那么你就只能从上次保存的地方继续。</li>
<li><strong>注意</strong>：如果使用了Ping Pong显存节省选项，那么你不应该将此值设置高于100，因为这样可能会伤害到最终的效果。</li>
</ul>
</li>
<li>Snapshot Interval<ul>
<li>快照是模型在某一个时间点的复制。如果你不满意模型当前的发展方向那么快照允许你回滚到一个早期的时间点的快照，或者在你的模型保存文件错误且没有备份的情况下通过快照回滚。由于创建快照点需要一些时间且期间模型不会进行训练，所以通常应当设置一个较高的值（默认值适用于大多数情况）。</li>
</ul>
</li>
</ul>
</li>
<li><p>Preview</p>
<ul>
<li>显示训练进程预览窗口的设置。</li>
<li>如果你是使用GUI那通常你不需要进行这些设置。预览是用来显示训练进程的一个弹出窗口。而GUI模式已经将这些信息嵌入到了“Display”面板，弹出的窗口只会显示完全相同的信息故而显得多余。预览将会在每次迭代保存时更新。</li>
<li>Preview Scale<ul>
<li>由于弹出的预览会自适应训练图像的尺寸，如果训练图像为256px，那么完整的预览窗口将会达到3072*1792，这对于大多数显示器来讲都过大，因此这个选项用于按百分比缩小预览。</li>
</ul>
</li>
<li>Preview<ul>
<li>勾选使能弹出预览窗口，不勾选则禁止弹出预览窗口。对于使用GUI的情况则通常不需要勾选。</li>
</ul>
</li>
<li>Write Image<ul>
<li>这能将预览图片写入facesawp文件夹。用于在没有显示器的设备（例如远端服务器）上进行训练。</li>
</ul>
</li>
</ul>
</li>
<li><p>Timelapse</p>
<ul>
<li>用于生成一组可选的延时图像的设置。</li>
<li>延时选项是一个可选的特性，能够让你看到训练过程中人脸随时间的变化。每次保存迭代时就会及时的保存一张展示当前训练进度的你选择的人脸图像。请注意延时图像所占用的磁盘空间会随着时间累计。</li>
<li>Timelapse Input A<ul>
<li>一个包含你想用来生成训练集A（原始人脸）的延时图像的人脸数据文件夹。只有前14张人脸数据会被使用。你也可以直接指向训练集A的文件夹，如果你希望选择训练集A的前14张人脸作为输入。</li>
</ul>
</li>
<li>Timelapse Input B<ul>
<li>一个包含你想用来生成训练集B（交换人脸）的延时图像的人脸数据文件夹。只有前14张人脸数据会被使用。你也可以直接指向训练集B的文件夹，如果你希望选择训练集B的前14张人脸作为输入。</li>
</ul>
</li>
<li>Timelapse Output<ul>
<li>保存生成的延时图像的文件夹。如果你填了前两项但是此项留空，那么默认会用你保存模型的文件夹。</li>
</ul>
</li>
</ul>
</li>
<li><p>Global</p>
<ul>
<li>Faceswap全局选项。</li>
<li>这里的选项对于faceswap的每个部分都有用而不只是用于训练。</li>
<li>Configfile<ul>
<li>你可以指定一个自定义的train.ini文件而不是使用保存在faceswap/config文件夹中的文件。如果你需要在很多已知的不同的好配置中间进行切换，那么这个选项是对你有用的。</li>
</ul>
</li>
<li>Loglevel<ul>
<li>Faceswap日志记录的级别。通常应设置为INFO等级。只有在开发者需求的条件下你可以将其设置为TRACE等级，这会明显的降低训练速度且生成大量的日志文件。</li>
<li><strong>注意</strong>：控制台只会显示到VERBOSE级别的信息，DEBUG和TRACE级别的信息只会写入日志文件。</li>
</ul>
</li>
<li>Logfile<ul>
<li>默认日志存储在faceswap/faceswap.log文件中，如果你愿意你也可以指明一个不同的位置。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>一旦你设置且确定好了所有你想要的配置，点击Train按钮开始训练。</p>
<h4 id="监督训练"><a href="#监督训练" class="headerlink" title="监督训练"></a>监督训练</h4><p>一旦你点击开始训练，训练进程将会花费一到两分钟去建立模型，预先加载数据然后启动训练。当训练启动后，GUI会进入到训练模式，底部将会出现一个状态栏，界面右侧将会出现一些标签页。</p>
<ul>
<li><p>Status Bar</p>
<ul>
<li>出现在底部右侧的状态栏会给出当前训练进度的一个预览，并会在每次迭代时更新。</li>
<li>你不需要太多关注这里的丢失数值。对于换脸来说它们是毫无意义的。这些数字只是显示了深度网络重建人脸A和人脸B的效果，但我们关注的是模型从人脸A的编码中建立人脸B的能力如何，而关于此效果的丢失值是不可能得到的，因为没有一个交换人脸的现实例子能供深度网络进行比较。</li>
<li>Elapsed<ul>
<li>当前训练阶段已经过去的时间。</li>
</ul>
</li>
<li>Session Iterations<ul>
<li>在当前训练阶段中已经完成的迭代次数。</li>
</ul>
</li>
<li>Total Iterations<ul>
<li>针对该模型的所有训练阶段已经完成的迭代总数。</li>
</ul>
</li>
<li>Loss A/Loss B<ul>
<li>本次迭代的丢失。</li>
<li><strong>注意</strong>：可能会有多个丢失值（例如人脸，面罩，多个输入等等）。该值为所有丢失的总和，因此这个数字差别变化会很大。</li>
</ul>
</li>
</ul>
</li>
<li><p>Preview Tab</p>
<ul>
<li>可视化模型当前的状态。这里表示模型重建和交换人脸的能力，每次模型保存时更新。</li>
<li>了解模型是否完成训练最好的办法就是查看预览。这里会显示最终实际看起来的交换效果。当你对预览的效果感到满意时就可以停止训练了。像眼部光泽和牙齿这些精细的细节会是最后要完成的事情，一旦这些都被做好了，那么通常就表示训练基本上完成了。</li>
<li>预览将会显示12列，前6列表示训练集A（原始人脸），后6列表示训练集B（交换人脸），6列又会分为2组，每组3列。<ul>
<li>组内第一列是未改变的输入模型图像。</li>
<li>组内第二列是模型尝试重建的人脸图像。</li>
<li>组内第三列是模型尝试进行交换的人脸图像。</li>
</ul>
</li>
<li>这会以纯色块，或者非常模糊的色块作为开始，随着深度网络逐渐学习如何重建和交换人脸，效果也会随之提升。</li>
<li>红色的不透明区域表示面罩之外的人脸区域（如果使用了面罩进行训练）。</li>
<li>如果使用小于100%的覆盖率进行训练，你会看到一个红框的边缘，这表明这部分是“换脸区域”或是正被神经网络用于训练的区域。</li>
<li>你可以用底部右侧的保存按钮来保存当前预览图像的副本。</li>
<li>可以通过取消勾选底部右侧的“Enable Preview”选项来禁用预览。</li>
</ul>
</li>
<li><p>Graph Tab</p>
<ul>
<li>这个标签页包含了一个以时间为轴的丢失值图表。在每次模型保存时更新，你也可以通过点击“Refresh”按钮手动刷新。</li>
<li>你不需要太多关注这里的丢失数值。对于换脸来说它们是毫无意义的。这些数字只是显示了深度网络重建人脸A和人脸B的效果，但我们关注的是模型从人脸A的编码中建立人脸B的能力如何，而关于此效果的丢失值是不可能得到的，因为没有一个交换人脸的现实例子能供深度网络进行比较。</li>
<li>丢失值图表依然是一个有用的工具。只要丢失值在下降，那么就表明模型依旧在学习。模型学习的速度会随着时间逐渐降低，因此到最后可能很难辨别模型是否依旧在继续学习。这种情况下就可以看分析标签页了。</li>
<li>基于输出的数值，可能会有好几个图表可用（例如总计丢失，面罩丢失，人脸丢失等）。每一个图表会展示各自的丢失输出。</li>
<li>你可以用底部右侧的保存按钮来保存当前预览图表的副本。</li>
<li>可以通过取消勾选底部右侧的“Enable Preview”选项来禁用图表。</li>
</ul>
</li>
<li><p>Analysis Tab</p>
<ul>
<li>这个标签页显示了当前运行和之前训练阶段的一些统计信息。</li>
<li>有如下列元素：<ul>
<li>Graphs<ul>
<li>点击蓝色图表图标打开选定的训练阶段图表。</li>
</ul>
</li>
<li>Start/End/Elapsed<ul>
<li>每个阶段各自的开始时间，结束时间和总训练时长。</li>
</ul>
</li>
<li>Batch<ul>
<li>每个阶段的输入批尺寸。</li>
</ul>
</li>
<li>Iterations<ul>
<li>每个阶段执行的总迭代次数。</li>
</ul>
</li>
<li>EGs/sec<ul>
<li>模型每秒钟处理的人脸图像个数。</li>
</ul>
</li>
</ul>
</li>
<li>当模型没有训练时，你可以通过点击底部右侧的“open”按钮打开模型文件夹，选择一个模型的state.json文件来查看之前训练的模型的信息。</li>
<li>你也可用通过底部右侧的“save”按钮来将分析标签页内的内容保存为CSV文件。</li>
<li>综上所述，丢失值图表对于查看丢失值是否下降有一定帮助，但当模型经过长时间训练后依旧难以分辨。分析标签页能给你一个更加详细的视图。</li>
<li>点击你最新训练阶段的蓝色图表图标会显示这个选定的阶段的训练图表。</li>
<li>选择“Show Smoothed”，将平滑值提高到0.99，点击“Refresh”按钮，然后就会放大最新的5000-10000此迭代。</li>
<li>现在图表已放大，你应该能够确定丢失值是否持续下降，或者它是否已“收敛（converged）”。收敛即指模型不再学习任何东西。</li>
</ul>
</li>
</ul>
<h4 id="停止与恢复"><a href="#停止与恢复" class="headerlink" title="停止与恢复"></a>停止与恢复</h4><p>在GUI的底部左侧按一下“Terminate”按钮就可以随时停止训练，模型将会保存它当前的状态并退出。</p>
<p>配置相同的设置，以及将“Model Dir”设置为之前保存模型数据的相同文件夹就可以重启模型。通过GUI的”File”菜单或选项面板下的保存按钮来保存faceswap配置能让重启模型变得更加容易。</p>
<p>你能通过简单重载你的配置文件便开始继续训练。</p>
<p>训练文件夹里的人脸数据可以添加或删除，但请确保你在做任何改动之前先停止训练，然后再重启。如果你使用了“Warp to Landmarks”或面罩来进行训练，那么请确保你的校准文件也随着新增或删除人脸而进行了更新。</p>
<h4 id="修复错误模型"><a href="#修复错误模型" class="headerlink" title="修复错误模型"></a>修复错误模型</h4><p>有时模型会崩溃，这可能由多种原因导致，但可以通过预览中的所有人脸变为纯色/混色块以及丢失值突增到高位而且无法恢复来判断模型的崩溃。</p>
<p>Faceswap提供了一个简单的工具来快捷修复模型。备份保存了每次丢失值总体下降的迭代记录。可通过以下步骤恢复备份：</p>
<ol>
<li>从Tools菜单进入Restore标签页</li>
<li>设置Model Dir，这里选择你崩溃了的模型的存放位置。</li>
<li>点击“Restore”按钮，一旦修复完成你就可以从你最新的备份处继续训练。</li>
</ol>

      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/record/">record</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tool/" rel="tag">tool</a></li></ul>

      
        
	<div id="comment">
	
	<!-- gitalk start -->
	<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
	<div id="gitalk-container"></div>
	<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
	<script type="text/javascript">
		var gitalk = new Gitalk({
			clientID: '6a3bfced9fed2761536e',
			clientSecret: '4771b2b0583e0359a1e2af05d70721a77fbcdc66',
			id: window.location.pathname,
			repo: 'PageHexoComments',
			owner: 'jiangfengringo',
			admin: 'jiangfengringo',
			perPage: 10,
			createIssueManually: false,
			distractionFreeMode: true
		})
		gitalk.render('gitalk-container')
	</script>
    </script>
	<!-- gitalk end -->
	
	</div>
	
<link rel="stylesheet" href="/css/comment.css">



      
    </footer>
    <hr class="entry-footer-hr">
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/04/07/%E7%97%85%E6%AF%92%E8%87%B4%E6%AD%BB%E5%8C%BA%E5%9F%9F%E5%87%8F%E7%BC%93%EF%BC%8C%E4%BD%86%E8%8B%B1%E5%9B%BD%E9%A6%96%E7%9B%B8%E6%AF%8F%E5%86%B5%E6%84%88%E4%B8%8B/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          病毒致死区域减缓，但英国首相每况愈下
        
      </div>
    </a>
  
  
    <a href="/2020/03/30/faceswap%E6%8F%90%E5%8F%96%EF%BC%9A%E4%B8%80%E7%A7%8D%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">faceswap提取：一种工作流程</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
      <ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#内容"><span class="nav-number">1.</span> <span class="nav-text">内容:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#介绍"><span class="nav-number">2.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#什么是训练？"><span class="nav-number">3.</span> <span class="nav-text">什么是训练？</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#概览"><span class="nav-number">3.1.</span> <span class="nav-text">概览</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#术语"><span class="nav-number">3.2.</span> <span class="nav-text">术语</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#训练数据"><span class="nav-number">4.</span> <span class="nav-text">训练数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#选择模型"><span class="nav-number">5.</span> <span class="nav-text">选择模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#配置模型"><span class="nav-number">6.</span> <span class="nav-text">配置模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#设置"><span class="nav-number">7.</span> <span class="nav-text">设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#监督训练"><span class="nav-number">8.</span> <span class="nav-text">监督训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#停止与恢复"><span class="nav-number">9.</span> <span class="nav-text">停止与恢复</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#修复错误模型"><span class="nav-number">10.</span> <span class="nav-text">修复错误模型</span></a></li></ol>
    
    </div>
  </aside>
</section>
        
      </div>

    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    <footer id="footer" class="site-footer">
  

  <div class="clearfix container">
      <div class="site-info">
	      &copy; 2020 IKEOVE All Rights Reserved.
        
            <span id="busuanzi_container_site_uv">
              This site has been load by <span id="busuanzi_value_site_uv"></span> person,  
              The total number of visits is <span id="busuanzi_value_site_pv"></span>.
            </span>
          
      </div>
      <div class="site-credit">
        Theme by <a href="https://github.com/iTimeTraveler/hexo-theme-hipaper" target="_blank">hipaper</a>
      </div>
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");

    wrapdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";
    contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";


    <!-- headerblur min height -->
    
    
</script>
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


<script src="/js/bootstrap.js"></script>


<script src="/js/main.js"></script>







	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>




  </div>

  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js" async=""></script>
</body>
</html>
